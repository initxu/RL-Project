{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bufang/anaconda3/envs/rl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video_1': 'AwmHb44_ouw',\n",
       " 'video_10': 'akI8YFjEmUw',\n",
       " 'video_11': 'i3wAGJaaktw',\n",
       " 'video_12': 'Bhxk-O1Y7Ho',\n",
       " 'video_13': '0tmA_C6XwfM',\n",
       " 'video_14': '3eYKfiOEJNs',\n",
       " 'video_15': 'xxdtq8mxegs',\n",
       " 'video_16': 'WG0MBPpPC6I',\n",
       " 'video_17': 'Hl-__g2gn_A',\n",
       " 'video_18': 'Yi4Ij2NM7U4',\n",
       " 'video_19': '37rzWOQsNIw',\n",
       " 'video_2': '98MoyGZKHXc',\n",
       " 'video_20': 'LRw_obCPUt0',\n",
       " 'video_21': 'cjibtmSLxQ4',\n",
       " 'video_22': 'b626MiF1ew4',\n",
       " 'video_23': 'XkqCExn6_Us',\n",
       " 'video_24': 'GsAD1KT1xo8',\n",
       " 'video_25': 'PJrm840pAUI',\n",
       " 'video_26': '91IHQYk1IQM',\n",
       " 'video_27': 'RBCABdttQmI',\n",
       " 'video_28': 'z_6gVvQb2d0',\n",
       " 'video_29': 'fWutDQy1nnY',\n",
       " 'video_3': 'J0nA4VgnoCo',\n",
       " 'video_30': '4wU_LUjG5Ic',\n",
       " 'video_31': 'VuWGsYPqAX8',\n",
       " 'video_32': 'JKpqYvAdIsw',\n",
       " 'video_33': 'xmEERLqJ2kU',\n",
       " 'video_34': 'byxOvuiIJV0',\n",
       " 'video_35': '_xMr-HKMfVA',\n",
       " 'video_36': 'WxtbjNsCQ8A',\n",
       " 'video_37': 'uGu_10sucQo',\n",
       " 'video_38': 'EE-bNr36nyA',\n",
       " 'video_39': 'Se3oxnaPsz0',\n",
       " 'video_4': 'gzDbaEs1Rlg',\n",
       " 'video_40': 'oDXZc0tZe04',\n",
       " 'video_41': 'qqR6AEXwxoQ',\n",
       " 'video_42': 'EYqVtI9YWJA',\n",
       " 'video_43': 'eQu1rNs0an0',\n",
       " 'video_44': 'JgHubY5Vw3Y',\n",
       " 'video_45': 'iVt07TCkFM0',\n",
       " 'video_46': 'E11zDS9XGzg',\n",
       " 'video_47': 'NyBmCxDoHJU',\n",
       " 'video_48': 'kLxoNp-UchI',\n",
       " 'video_49': 'jcoYJXDG9sw',\n",
       " 'video_5': 'XzYM3PfTM4w',\n",
       " 'video_50': '-esJrBWj2d8',\n",
       " 'video_6': 'HT5vyqe0Xaw',\n",
       " 'video_7': 'sTEELN-vY30',\n",
       " 'video_8': 'vdmoEJ5YbrQ',\n",
       " 'video_9': 'xwqBXPGE9pQ'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvsum_video_ls=['video_1', 'video_10', 'video_11', 'video_12', 'video_13', 'video_14', 'video_15', 'video_16', 'video_17', 'video_18', 'video_19', 'video_2', 'video_20', 'video_21', 'video_22', 'video_23', 'video_24', 'video_25', 'video_26', 'video_27', 'video_28', 'video_29', 'video_3', 'video_30', 'video_31', 'video_32', 'video_33', 'video_34', 'video_35', 'video_36', 'video_37', 'video_38', 'video_39', 'video_4', 'video_40', 'video_41', 'video_42', 'video_43', 'video_44', 'video_45', 'video_46', 'video_47', 'video_48', 'video_49', 'video_5', 'video_50', 'video_6', 'video_7', 'video_8', 'video_9']\n",
    "tvsum_video_name_ls=['AwmHb44_ouw','akI8YFjEmUw','i3wAGJaaktw','Bhxk-O1Y7Ho','0tmA_C6XwfM','3eYKfiOEJNs','xxdtq8mxegs','WG0MBPpPC6I','Hl-__g2gn_A','Yi4Ij2NM7U4','37rzWOQsNIw','98MoyGZKHXc','LRw_obCPUt0','cjibtmSLxQ4','b626MiF1ew4','XkqCExn6_Us','GsAD1KT1xo8','PJrm840pAUI','91IHQYk1IQM','RBCABdttQmI','z_6gVvQb2d0','fWutDQy1nnY','J0nA4VgnoCo','4wU_LUjG5Ic','VuWGsYPqAX8','JKpqYvAdIsw','xmEERLqJ2kU','byxOvuiIJV0','_xMr-HKMfVA','WxtbjNsCQ8A','uGu_10sucQo','EE-bNr36nyA','Se3oxnaPsz0','gzDbaEs1Rlg','oDXZc0tZe04','qqR6AEXwxoQ','EYqVtI9YWJA','eQu1rNs0an0','JgHubY5Vw3Y','iVt07TCkFM0','E11zDS9XGzg','NyBmCxDoHJU','kLxoNp-UchI','jcoYJXDG9sw','XzYM3PfTM4w','-esJrBWj2d8','HT5vyqe0Xaw','sTEELN-vY30','vdmoEJ5YbrQ','xwqBXPGE9pQ']\n",
    "\n",
    "tvsum_video_dict = dict(zip(tvsum_video_ls, tvsum_video_name_ls))\n",
    "tvsum_video_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video_1': 'Air_Force_One',\n",
       " 'video_10': 'Excavators_river_crossing',\n",
       " 'video_11': 'Fire_Domino',\n",
       " 'video_12': 'Jumps',\n",
       " 'video_13': 'Kids_playing_in_leaves',\n",
       " 'video_14': 'Notre_Dame',\n",
       " 'video_15': 'Paintball',\n",
       " 'video_16': 'Playing_on_water_slide',\n",
       " 'video_17': 'Saving_dolphines',\n",
       " 'video_18': 'Scuba',\n",
       " 'video_19': 'St_Maarten_Landing',\n",
       " 'video_2': 'Base_jumping',\n",
       " 'video_20': 'Statue_of_Liberty',\n",
       " 'video_21': 'Uncut_Evening_Flight',\n",
       " 'video_22': 'Valparaiso_Downhill',\n",
       " 'video_23': 'car_over_camera',\n",
       " 'video_24': 'paluma_jump',\n",
       " 'video_25': 'playing_ball',\n",
       " 'video_3': 'Bearpark_climbing',\n",
       " 'video_4': 'Bike_Polo',\n",
       " 'video_5': 'Bus_in_Rock_Tunnel',\n",
       " 'video_6': 'Car_railcrossing',\n",
       " 'video_7': 'Cockpit_Landing',\n",
       " 'video_8': 'Cooking',\n",
       " 'video_9': 'Eiffel_Tower'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summe_video_ls=['video_1', 'video_10', 'video_11', 'video_12', 'video_13', 'video_14', 'video_15', 'video_16', 'video_17', 'video_18', 'video_19', 'video_2', 'video_20', 'video_21', 'video_22', 'video_23', 'video_24', 'video_25', 'video_3', 'video_4', 'video_5', 'video_6', 'video_7', 'video_8', 'video_9']\n",
    "summe_video_name_ls=['Air_Force_One', 'Excavators_river_crossing', 'Fire_Domino', 'Jumps', 'Kids_playing_in_leaves', 'Notre_Dame', 'Paintball', 'Playing_on_water_slide', 'Saving_dolphines', 'Scuba', 'St_Maarten_Landing', 'Base_jumping', 'Statue_of_Liberty', 'Uncut_Evening_Flight', 'Valparaiso_Downhill', 'car_over_camera', 'paluma_jump', 'playing_ball', 'Bearpark_climbing', 'Bike_Polo', 'Bus_in_Rock_Tunnel', 'Car_railcrossing', 'Cockpit_Landing', 'Cooking', 'Eiffel_Tower']\n",
    "summe_video_dict = dict(zip(summe_video_ls, summe_video_name_ls))\n",
    "summe_video_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smodel_map={\n",
    "    'all-mpnet-base-v2':'mpnet', # 768\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='summe'\n",
    "llava_version='llava-v1.6-mistral-7b-hf'\n",
    "prompt_version='v1'\n",
    "model_name='all-mpnet-base-v2'\n",
    "model = SentenceTransformer(model_name)\n",
    "model_folder=smodel_map[model_name]\n",
    "\n",
    "for video in summe_video_ls:\n",
    "    video_name=summe_video_dict[video]\n",
    "    caption_file_pth=f'./{dataset}/{llava_version}/{prompt_version}/{video_name}.json'\n",
    "    with open(caption_file_pth, 'r') as file:\n",
    "        caption_data = json.load(file)\n",
    "        img_captions = [entry[\"img_caption\"] for entry in caption_data]\n",
    "\n",
    "            \n",
    "    embeddings = model.encode(img_captions)\n",
    "    embedding_pth=f'./text_embedding/{dataset}/{llava_version}/{prompt_version}/{model_folder}/{video}.npy'\n",
    "    np.save(embedding_pth, embeddings)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='tvsum'\n",
    "llava_version='llava-v1.6-mistral-7b-hf'\n",
    "prompt_version='v1' \n",
    "model_name='all-mpnet-base-v2'\n",
    "model = SentenceTransformer(model_name)\n",
    "model_folder=smodel_map[model_name]\n",
    "\n",
    "for video in tvsum_video_ls:\n",
    "    video_name=tvsum_video_dict[video]\n",
    "    caption_file_pth=f'./{dataset}/{llava_version}/{prompt_version}/{video_name}.json'\n",
    "    with open(caption_file_pth, 'r') as file:\n",
    "        caption_data = json.load(file)\n",
    "        img_captions = [entry[\"img_caption\"] for entry in caption_data]\n",
    "\n",
    "            \n",
    "    embeddings = model.encode(img_captions)\n",
    "    embedding_pth=f'./text_embedding/{dataset}/{llava_version}/{prompt_version}/{model_folder}/{video}.npy'\n",
    "    np.save(embedding_pth, embeddings)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='summe'\n",
    "llava_version='llava-v1.6-mistral-7b-hf'\n",
    "caption_folder='v1_summary' \n",
    "prompt_version='v1'\n",
    "model_name='all-mpnet-base-v2'\n",
    "model = SentenceTransformer(model_name)\n",
    "model_folder=smodel_map[model_name]\n",
    "\n",
    "for video in summe_video_ls:\n",
    "    video_name=summe_video_dict[video]\n",
    "    caption_file_pth=f'./{dataset}/{llava_version}/{caption_folder}/{video_name}.json'\n",
    "    with open(caption_file_pth, 'r') as file:\n",
    "        caption_data = json.load(file)\n",
    "        caption_summary = [entry[\"caption_summary\"] for entry in caption_data][0]\n",
    "\n",
    "            \n",
    "    embeddings = model.encode(caption_summary)\n",
    "    embedding_pth=f'./text_embedding/{dataset}/{llava_version}/{prompt_version}/{model_folder}/{caption_folder}/{video}.npy'\n",
    "    np.save(embedding_pth, embeddings)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='tvsum'\n",
    "llava_version='llava-v1.6-mistral-7b-hf'\n",
    "caption_folder='v1_summary' \n",
    "prompt_version='v1'\n",
    "model_name='all-mpnet-base-v2'\n",
    "model = SentenceTransformer(model_name)\n",
    "model_folder=smodel_map[model_name]\n",
    "\n",
    "for video in tvsum_video_ls:\n",
    "    video_name=tvsum_video_dict[video]\n",
    "    caption_file_pth=f'./{dataset}/{llava_version}/{caption_folder}/{video_name}.json'\n",
    "    with open(caption_file_pth, 'r') as file:\n",
    "        caption_data = json.load(file)\n",
    "        caption_summary = [entry[\"caption_summary\"] for entry in caption_data][0]\n",
    "\n",
    "            \n",
    "    embeddings = model.encode(caption_summary)\n",
    "    embedding_pth=f'./text_embedding/{dataset}/{llava_version}/{prompt_version}/{model_folder}/{caption_folder}/{video}.npy'\n",
    "    np.save(embedding_pth, embeddings)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
